{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad 4: Selección del mejor modelo de ML\n",
        "\n",
        "Durante la etapa de entrenamiento nos podemos encontrar con diferentes estrategias de cara a mejorar el desempeño del modelo. Una de estas estrategias es conocida como **Model Selection**, en la cual, probamos con diferentes algoritmos de Machine Learning y al final, escogemos el mejor modelo con base al que obtenga las mejores métricas. Para esta actividad, seguiremos con el mismo caso de uso descrito en la Actividad 3, que es la clasificación de cancer de mama entre los tipos **Maligno y Benigno**.\n",
        "\n",
        "En la pasada actividad usamos SVM como clasificador, en esta Activdad 3, evaluaremos el desempeño del modelo al usar 3 clasificadores diferentes, que son: **LightGBM, MLPClassifier (perceptrón multicapa) y Logistic Regression**. Al final, tomaremos el mejor modelo con base en el mejor **Accuracy**"
      ],
      "metadata": {
        "id": "GCU1CNRa9mRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports \n",
        "\n",
        "Librerias que se necesitan para el desarrollo de la actividad"
      ],
      "metadata": {
        "id": "c-shzmd4AmIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import lightgbm as ltb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "FF1EG-nJAqDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurando pandas para visualización de 100 columnas"
      ],
      "metadata": {
        "id": "bXkGsATgO70J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = 100"
      ],
      "metadata": {
        "id": "eT5054F4PD0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectura del dataset"
      ],
      "metadata": {
        "id": "DGsQJqk2PWu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://raw.githubusercontent.com/eyberthrojas/Actividad-4-ML-/main/is_cancer.csv'\n",
        "data = pd.read_csv(path, on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "KL6aWwQQPccY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento del modelo\n",
        "\n",
        "Lo descrito en esta sección es reutilizado de la Actividad anterior como base para la evaluación de diferentes clasificadores."
      ],
      "metadata": {
        "id": "Qka2uUOfK2tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_finales = [\n",
        "    \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\",\n",
        "    \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\", \n",
        "    \"fractal_dimension_mean\", \"diagnosis\"\n",
        "]"
      ],
      "metadata": {
        "id": "3IA3N4UuZvHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionamos solo las features de interés del dataset completo\n",
        "dataset_final = data[features_finales]"
      ],
      "metadata": {
        "id": "ZLEMJS7UZvKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable categórica creada a partir de la feature fractal_dimension_mean. \n",
        "dataset_final[\"calc_fractal_dimension_mean\"] = np.where(\n",
        "    1, dataset_final[\"fractal_dimension_mean\"] < 0.055, \n",
        "    0\n",
        ")"
      ],
      "metadata": {
        "id": "FSyMCjxPc5Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos la variable númerica que usamos para crear la variable categórica\n",
        "dataset_final.drop(['fractal_dimension_mean'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "L5jrV934d3vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase que realiza el fit y transform a una variable\n",
        "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Select only specified columns.\"\"\"\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        return X[self.columns]"
      ],
      "metadata": {
        "id": "qmbH7TCwgmCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features numéricas\n",
        "numerical = [\n",
        "    \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\",\n",
        "    \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\"\n",
        "]"
      ],
      "metadata": {
        "id": "w2yUuN1fgDAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ColumnSelector: selecciona las columnas númericas del dataset de entrenamiento\n",
        "# SimpleImputer: los valores faltantes los completa con la mediana de todos los valores de la feature\n",
        "num_pipe = Pipeline([\n",
        "    ('selector', ColumnSelector(numerical)),\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "])"
      ],
      "metadata": {
        "id": "m6j4lcW2f-yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features categóricas\n",
        "categorical = [\"calc_fractal_dimension_mean\"]"
      ],
      "metadata": {
        "id": "ecqv0ZihhlYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ColumnSelector: selecciona las columnas categóricas del dataset de entrenamiento\n",
        "# SimpleImputer: los valores faltantes los completa con un valor fijo\n",
        "# OneHotEncoder: codificación de variables categóricas\n",
        "cat_pipe = Pipeline([\n",
        "    ('selector', ColumnSelector(categorical)),\n",
        "    ('imputer', SimpleImputer(strategy='constant')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "])"
      ],
      "metadata": {
        "id": "jAoMZVvUf-09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature union de todas las features categóricas y numéricas\n",
        "preprocessor = FeatureUnion([\n",
        "    ('cat', cat_pipe),\n",
        "    ('num', num_pipe)\n",
        "])"
      ],
      "metadata": {
        "id": "MXjnhQxgiRlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se elimina la variable target de los datos que contienen las features \n",
        "X = dataset_final.drop(['diagnosis'], axis = 1)"
      ],
      "metadata": {
        "id": "n5_ey64Vf-3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera en una variable separada el target del problema, en este caso \"Diagnosis\"\n",
        "y = dataset_final['diagnosis']"
      ],
      "metadata": {
        "id": "2ViNw4x5isv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# De todo el conjunto de datos se toman crean datos de train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
        "print(\"Size of training set:\", X_train.shape)\n",
        "print(\"Size of test set:\", X_test.shape)"
      ],
      "metadata": {
        "id": "WW5R_AWeiy7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación de LightGBM"
      ],
      "metadata": {
        "id": "Er50aVUmEVhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación LightGBM\n",
        "!pip install lightgbm"
      ],
      "metadata": {
        "id": "d9Zrf_1uE78k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline \n",
        "pipe_lightgbm = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', ltb.LGBMClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "_CrWCM-0D64d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model_lightgbm = pipe_lightgbm.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Gk_1lckCECLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción sobre los datos de test\n",
        "y_pred = model_lightgbm.predict(X_test)"
      ],
      "metadata": {
        "id": "NpnzYXYKECoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report de resultados al usar LightGBM\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "id": "KR1kZKXIFcsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Se puede observar que en un primera iteración, al usar LightGBM se obtiene un mejor accuracy respecto a lo obtenido en la actividad anterior usando SVM. A partir de esto, ya queda a criterio del científico de datos hacer uso de búsqueda de hiperaparámetros. Este paso tambien depende si la métrica obtenida es igual o mayor a la superior. Para esta actividad, tomaremos el accuracy mas alto*"
      ],
      "metadata": {
        "id": "Dp38tJuEH6pm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación de MLPClassifier"
      ],
      "metadata": {
        "id": "p2HYAxQcIpbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline\n",
        "pipe_mlp = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', MLPClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "iNGlskr6IqiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model_mlp = pipe_mlp.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "_BtWf053IuZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción sobre los datos de test\n",
        "y_pred = model_mlp.predict(X_test)"
      ],
      "metadata": {
        "id": "rD7bcWYNI3Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report de resultados al usar MLPClassifier\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "id": "U8ZFUyuII9zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar que se obtiene un accuracy del 0.91, la cual es menor que la obtenida por LightGBM e igual a la obtenida en la actividad anterior. Haremos una optimización de hiperaparámetros para intentar aumentar esta métrica"
      ],
      "metadata": {
        "id": "q_MfnD5VcU5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rango de hiperparámetros\n",
        "mlp_gs = MLPClassifier(max_iter=100)\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive']\n",
        "}"
      ],
      "metadata": {
        "id": "ZIh1CfpsJA0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Búsqueda de los mejores hiperparámetros\n",
        "clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "tj5y7RtPQfqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hipaparámetros encontrados por GirdSearch para MLPClassifier\n",
        "clf.best_params_"
      ],
      "metadata": {
        "id": "0xCgKTEQQSbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciamento del modelo con los hiperparámetros encontrados\n",
        "clf = MLPClassifier(**clf.best_params_)"
      ],
      "metadata": {
        "id": "zzFZ-tm3QvHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline con nuevos hiperparámetros\n",
        "pipe_mlp = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', clf)\n",
        "])"
      ],
      "metadata": {
        "id": "e9j_nff2QrDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model_mlp = pipe_mlp.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "DNtnIFlqRAcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción sobre los datos de test\n",
        "y_pred = model_mlp.predict(X_test)"
      ],
      "metadata": {
        "id": "rX_paputRDzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas con hiperparámetros encontrados\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "id": "6YbkTSXRRGKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que en términos de accuracy, se obtiene un valor menor a los obtenidos en iteraciones anteriores."
      ],
      "metadata": {
        "id": "G7zaNqT5dI4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación de Logistic Regression"
      ],
      "metadata": {
        "id": "V8iZGy7USKfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline final del proceso de entrenamiento\n",
        "pipe_lr = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', LogisticRegression())\n",
        "])"
      ],
      "metadata": {
        "id": "g_u9qiWqSPQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model_lr = pipe_lr.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "_u4T15D7SeK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción sobre los datos de test\n",
        "y_pred = model_lr.predict(X_test)"
      ],
      "metadata": {
        "id": "o-kRRCk1SjXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report de resultados al usar LogisticRegression\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "id": "BpTkQTa9Sm-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También, se puede observar que se obtiene un accuracy del 0.91, la cual es menor que la obtenida por LightGBM y igual a la obtenida en la actividad anterior. Nuevamente, haremos una optimización de hiperaparámetros para intentar aumentar esta métrica."
      ],
      "metadata": {
        "id": "hREl8G5MdhqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rango de hiperparámetros\n",
        "parameters = {\n",
        "    \"C\":np.logspace(-3,3,7), \n",
        "    \"penalty\":[\"l2\"], \n",
        "    \"solver\":['liblinear','newton-cg']\n",
        "}"
      ],
      "metadata": {
        "id": "XDoRX28WSovM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Búsqueda de los mejores hiperparámetros\n",
        "clf = GridSearchCV(LogisticRegression(), param_grid = parameters, cv = 5, verbose=True, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "mknqmBHoTBee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros encontrados\n",
        "clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJr9apLwT1-J",
        "outputId": "4087f127-e0a9-4f10-90b1-dac1463bd93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline con nuevos hiperparametros\n",
        "pipe_lr = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', LogisticRegression(**clf.best_params_))\n",
        "])"
      ],
      "metadata": {
        "id": "r4grn9NrUfIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model_lr = pipe_lr.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "OYzeO_8IUoLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción sobre los datos de test\n",
        "y_pred = model_lr.predict(X_test)"
      ],
      "metadata": {
        "id": "KFoMPQy2UqEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas con nuevos hiperparametros\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "id": "U0koihstUrwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar, que para LogisticRegression se obtiene un mayor accuracy, 0.94. Es un accuracy alto, sin embargo, es menor al obtenido por LightGBM. "
      ],
      "metadata": {
        "id": "l0h1uECFeKKF"
      }
    }
  ]
}